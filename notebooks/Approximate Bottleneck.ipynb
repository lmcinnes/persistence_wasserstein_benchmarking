{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate Bottleneck Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import scipy.stats\n",
    "import sklearn.metrics\n",
    "from sklearn.cluster import KMeans\n",
    "import numba\n",
    "import matplotlib.pyplot as plt\n",
    "import ot\n",
    "import umap\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding more example diagrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teaspoon.MakeData.PointCloud import testSetManifolds \n",
    "from teaspoon.TDA.Distance import dgmDist_Hera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Were are going to generate 10 small examples from each of the 6 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating torus clouds...\n",
      "Generating annuli clouds...\n",
      "Generating cube clouds...\n",
      "Generating three cluster clouds...\n",
      "Generating three clusters of three clusters clouds...\n",
      "Generating sphere clouds...\n",
      "Finished generating clouds and computing persistence.\n",
      "\n",
      "CPU times: user 18.7 s, sys: 110 ms, total: 18.8 s\n",
      "Wall time: 4.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "manifoldData = testSetManifolds(numDgms = 10, numPts = 300, permute = False, seed = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are just going to consider the 1-dimension persistence \n",
    "\n",
    "# In birth-death\n",
    "JustDgms_death = list(manifoldData['Dgm1'])\n",
    "# In birth-lifetime\n",
    "JustDgms_lifetime = [np.concatenate([[X[:,0]],[X[:,1]-X[:,0]]], axis = 0).T for X in JustDgms_death]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the wasserstein code... We can take a p and a q, where the q is the internal p for L_p norms. We need to work with the infinite case, but that can easily be handled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_diagram_distance(pts0, pts1, y_axis='death', p=1, q=2):\n",
    "    '''\n",
    "    Compute the Persistant p-Wasserstein distance between the diagrams pts0, pts1\n",
    "    \n",
    "    y_axis = 'death' (default), or 'lifetime'\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if y_axis == 'lifetime':\n",
    "        extra_dist0 = pts0[:, 1]\n",
    "        extra_dist1 = pts1[:, 1]\n",
    "    elif y_axis == 'death':    \n",
    "        extra_dist0 = (pts0[:, 1] - pts0[:, 0]) * (2 **((1.0 / q) - 1))\n",
    "        extra_dist1 = (pts1[:, 1] - pts1[:, 0]) * (2 **((1.0 / q) - 1))\n",
    "    else:\n",
    "        raise ValueError('y_axis must be \\'death\\' or \\'lifetime\\'')\n",
    "        \n",
    "    if np.isfinite(q):\n",
    "        pairwise_dist = sklearn.metrics.pairwise_distances(pts0, pts1, metric=\"minkowski\", p=q)\n",
    "    else:\n",
    "        pairwise_dist = sklearn.metrics.pairwise_distances(pts0, pts1, metric=\"chebyshev\")\n",
    "    \n",
    "    all_pairs_ground_distance_a = np.hstack([pairwise_dist, extra_dist0[:, np.newaxis]])\n",
    "    extra_row = np.zeros(all_pairs_ground_distance_a.shape[1])\n",
    "    extra_row[:pairwise_dist.shape[1]] = extra_dist1\n",
    "    all_pairs_ground_distance_a = np.vstack([all_pairs_ground_distance_a, extra_row])\n",
    "  \n",
    "    all_pairs_ground_distance_a = all_pairs_ground_distance_a**p\n",
    "    \n",
    "    n0 = pts0.shape[0]\n",
    "    n1 = pts1.shape[0]\n",
    "    a = np.ones(n0+1)\n",
    "    a[n0]=n1\n",
    "    a = a/a.sum()\n",
    "    b = np.ones(n1+1)\n",
    "    b[n1]=n0\n",
    "    b = b/b.sum()\n",
    "    \n",
    "    return np.power((n0+n1)*ot.emd2(a, b, all_pairs_ground_distance_a),1.0/p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifications to do approximate bottleneck\n",
    "\n",
    "Here we switch the metric to 'chebyshev' which is $L_\\infty$.  Also, the transport cost we want to return is the max cost to move any element given the transport plan - not the total cost.  Ideally if this was always a matching this would be the highest cost of an entry in this matrix but there could be mass splitting in the returned solution in theory so we sum up the total cost to move each element and then take the max of that to fix that issue.   \n",
    "\n",
    "Now, the optimal transport code is going to minimize total transport cost not the maximal transport cost, but in theory we can now take advantage of the limit and just raise all of the transport costs to the p-th power and find the optimal transport of that, which will basically be forced to minimize the maximal cost as a result.  Using this plan we compute the max cost under the original $L_\\infty$ cost matrix without the p-th powers and take the max row sum / col sum of that. \n",
    "\n",
    "Lastly, because we are grouping all of the points at infinity together we actually only want to find the maximal cost of moving one of the real points in one of the diagrams (which will be equal if they move to each other), so we have to take some care to remove the infinite points (the last row/columns) when we are summing looking for the most costly move; the sum along the bottom row is total cost of all the points in the second diagram that get moved to the diagonal, and similarly for the last column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_bottleneck_diagram_distance(pts0, pts1, y_axis='death', p=1):\n",
    "    '''\n",
    "    Compute the Persistant p-Wasserstein distance between the diagrams pts0, pts1\n",
    "    \n",
    "    y_axis = 'death' (default), or 'lifetime'\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if y_axis == 'lifetime':\n",
    "        extra_dist0 = pts0[:, 1]\n",
    "        extra_dist1 = pts1[:, 1]\n",
    "    elif y_axis == 'death':    \n",
    "        extra_dist0 = (pts0[:, 1]-pts0[:, 0])/2\n",
    "        extra_dist1 = (pts1[:, 1]-pts1[:, 0])/2\n",
    "    else:\n",
    "        raise ValueError('y_axis must be \\'death\\' or \\'lifetime\\'')\n",
    "        \n",
    "    pairwise_dist = sklearn.metrics.pairwise_distances(pts0, pts1, metric='chebyshev')\n",
    "    \n",
    "    all_pairs_ground_distance_a = np.hstack([pairwise_dist, extra_dist0[:, np.newaxis]])\n",
    "    extra_row = np.zeros(all_pairs_ground_distance_a.shape[1])\n",
    "    extra_row[:pairwise_dist.shape[1]] = extra_dist1\n",
    "    all_pairs_ground_distance_a = np.vstack([all_pairs_ground_distance_a, extra_row])\n",
    "  \n",
    "    all_pairs_ground_distance_ap = np.power(all_pairs_ground_distance_a,p)\n",
    "    \n",
    "    n0 = pts0.shape[0]\n",
    "    n1 = pts1.shape[0]\n",
    "    a = np.ones(n0+1)\n",
    "    a[n0]=n1\n",
    "    a = a/a.sum()\n",
    "    b = np.ones(n1+1)\n",
    "    b[n1]=n0\n",
    "    b = b/b.sum()\n",
    "    \n",
    "    T=ot.emd(a, b, all_pairs_ground_distance_ap)\n",
    "    \n",
    "    return (n0+n1)*np.max([np.max(np.sum(T[:-1,:]*all_pairs_ground_distance_a[:-1,:],axis=1)),\n",
    "                            np.max(np.sum(T[:,:-1]*all_pairs_ground_distance_a[:,:-1],axis=0))])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we expect no mass splitting this is Leland's solution which induces an actual matching from the plan since it rounds things to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_bottleneck_diagram_distance(pts0, pts1, y_axis='death', p=1):\n",
    "    '''\n",
    "    Compute the Persistant p-Wasserstein distance between the diagrams pts0, pts1\n",
    "    \n",
    "    y_axis = 'death' (default), or 'lifetime'\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if y_axis == 'lifetime':\n",
    "        extra_dist0 = pts0[:, 1]\n",
    "        extra_dist1 = pts1[:, 1]\n",
    "    elif y_axis == 'death':    \n",
    "        extra_dist0 = (pts0[:, 1] - pts0[:, 0]) / 2\n",
    "        extra_dist1 = (pts1[:, 1] - pts1[:, 0]) / 2\n",
    "    else:\n",
    "        raise ValueError('y_axis must be \\'death\\' or \\'lifetime\\'')\n",
    "        \n",
    "    pairwise_dist = sklearn.metrics.pairwise_distances(pts0, pts1, metric='chebyshev')\n",
    "    \n",
    "    transport_cost = np.hstack([pairwise_dist, extra_dist0[:, np.newaxis]])\n",
    "    extra_row = np.zeros(transport_cost.shape[1])\n",
    "    extra_row[:pairwise_dist.shape[1]] = extra_dist1\n",
    "    transport_cost = np.vstack([transport_cost, extra_row])\n",
    "  \n",
    "    transport_cost_p = np.power(transport_cost, p)\n",
    "    \n",
    "    n0 = pts0.shape[0]\n",
    "    n1 = pts1.shape[0]\n",
    "    a = np.ones(n0+1)\n",
    "    a[n0]=n1\n",
    "    a = a/a.sum()\n",
    "    b = np.ones(n1+1)\n",
    "    b[n1]=n0\n",
    "    b = b/b.sum()\n",
    "    \n",
    "    # We can just read off the max cost used in transport\n",
    "    transport_plan = (n0 + n1) * ot.emd(a, b, transport_cost_p)\n",
    "    return np.max(transport_cost[np.isclose(transport_plan, 1.0)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets see how this converges as we vary p \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_all_pairs_bottleneck_distance(diagrams, n=100, p=1):\n",
    "    bott_all_pairs_dist = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(i,n):\n",
    "            bott_all_pairs_dist[i,j] = approx_bottleneck_diagram_distance( \n",
    "                                                diagrams[i], diagrams[j], y_axis='death', p=p\n",
    "            )\n",
    "            bott_all_pairs_dist[j,i] = bott_all_pairs_dist[i,j]\n",
    "    return bott_all_pairs_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_all_pairs_bottleneck_distance(diagrams, n=100, p=1):\n",
    "    bott_all_pairs_dist = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(i,n):\n",
    "            bott_all_pairs_dist[i,j] = match_bottleneck_diagram_distance( \n",
    "                                                diagrams[i], diagrams[j], y_axis='death', p=p\n",
    "            )\n",
    "            bott_all_pairs_dist[j,i] = bott_all_pairs_dist[i,j]\n",
    "    return bott_all_pairs_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.8 s, sys: 150 ms, total: 34.9 s\n",
      "Wall time: 35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d_match=[match_all_pairs_bottleneck_distance(JustDgms_death, 60, p) for p in range(1,20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.3 s, sys: 177 ms, total: 34.4 s\n",
      "Wall time: 34.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d_approx=[approx_all_pairs_bottleneck_distance(JustDgms_death, 60, p) for p in range(1,20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [np.abs(d_match[p-1] - d_approx[p-1]) for p in range(1, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p  1 % 1.0 Error:  Max 3.8413716652030416e-14   Mean 8.90920246527433e-16\n",
      "p  2 % 1.0 Error:  Max 2.853273173286652e-14   Mean 7.929035514584213e-16\n",
      "p  3 % 1.0 Error:  Max 3.8413716652030416e-14   Mean 8.372026066232823e-16\n",
      "p  4 % 1.0 Error:  Max 3.8413716652030416e-14   Mean 8.054706593066087e-16\n",
      "p  5 % 1.0 Error:  Max 3.8413716652030416e-14   Mean 8.068141062652264e-16\n",
      "p  6 % 1.0 Error:  Max 3.8413716652030416e-14   Mean 8.0800335558153495e-16\n",
      "p  7 % 1.0 Error:  Max 2.853273173286652e-14   Mean 7.701324146304324e-16\n",
      "p  8 % 1.0 Error:  Max 2.853273173286652e-14   Mean 7.286436114966537e-16\n",
      "p  9 % 1.0 Error:  Max 3.8413716652030416e-14   Mean 8.133867807686497e-16\n",
      "p  10 % 1.0 Error:  Max 3.11972669919669e-14   Mean 7.337456259865544e-16\n",
      "p  11 % 1.0 Error:  Max 3.552713678800501e-14   Mean 8.076255713578778e-16\n",
      "p  12 % 1.0 Error:  Max 3.8413716652030416e-14   Mean 7.36243627791961e-16\n",
      "p  13 % 1.0 Error:  Max 3.552713678800501e-14   Mean 7.745193375541249e-16\n",
      "p  14 % 1.0 Error:  Max 3.8413716652030416e-14   Mean 7.864696548330761e-16\n",
      "p  15 % 1.0 Error:  Max 3.8413716652030416e-14   Mean 7.49986492662755e-16\n",
      "p  16 % 1.0 Error:  Max 3.552713678800501e-14   Mean 7.863231670728826e-16\n",
      "p  17 % 1.0 Error:  Max 3.352873534367973e-14   Mean 7.260858581048524e-16\n",
      "p  18 % 1.0 Error:  Max 2.8310687127941492e-14   Mean 7.480898616623538e-16\n",
      "p  19 % 1.0 Error:  Max 3.8413716652030416e-14   Mean 7.640647374055712e-16\n"
     ]
    }
   ],
   "source": [
    "for p in range(1, 20):\n",
    "    percent_correct = np.sum(np.isclose(errors[p-1], 0.0)) / 60.0**2\n",
    "    #print(f\"{p=}, {percent_correct=}, {np.max(errors[p-1])=}, {np.mean(errors[p-1])=}\")\n",
    "    print(\"p \",p, \"%\",percent_correct, \"Error:  Max\", np.max(errors[p-1]),  \"  Mean\", np.mean(errors[p-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both methods basically give the same results up to precision errors (there was no mass splitting which is little surprise). \n",
    "\n",
    "Now to compare to the correct solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import persim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persim_all_pairs_bottleneck_distance(diagrams, n=100):\n",
    "    bott_all_pairs_dist = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(i,n):\n",
    "            bott_all_pairs_dist[i,j] = persim.bottleneck(diagrams[i], diagrams[j])\n",
    "            bott_all_pairs_dist[j,i] = bott_all_pairs_dist[i,j]\n",
    "    return bott_all_pairs_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 57s, sys: 780 ms, total: 4min 58s\n",
      "Wall time: 4min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "persim_distances = persim_all_pairs_bottleneck_distance(JustDgms_death, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [np.abs(persim_distances - d_match[p-1]) for p in range(1, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p  1 % exact 80.55555555555556 Error:  Max 0.15655291080474865   Mean 0.003993318486545525\n",
      "p  2 % exact 93.83333333333333 Error:  Max 0.051955342292785645   Mean 0.0004415116210786263\n",
      "p  3 % exact 96.11111111111111 Error:  Max 0.05195534229278562   Mean 0.00021736337699906707\n",
      "p  4 % exact 97.33333333333334 Error:  Max 0.030719339847564475   Mean 0.00012309675829357973\n",
      "p  5 % exact 98.05555555555556 Error:  Max 0.02148166298866261   Mean 7.206694533507553e-05\n",
      "p  6 % exact 98.44444444444444 Error:  Max 0.02148166298866261   Mean 5.8784190980075584e-05\n",
      "p  7 % exact 98.77777777777777 Error:  Max 0.0095406174659729   Mean 3.2610889111067215e-05\n",
      "p  8 % exact 97.22222222222221 Error:  Max 0.0095406174659729   Mean 8.032467837207775e-05\n",
      "p  9 % exact 91.55555555555556 Error:  Max 0.025418624281883254   Mean 0.0006747377839775393\n",
      "p  10 % exact 84.0 Error:  Max 0.048307597637176514   Mean 0.0025294788823366846\n",
      "p  11 % exact 78.66666666666666 Error:  Max 0.08409188687801361   Mean 0.005956355015644568\n",
      "p  12 % exact 75.44444444444444 Error:  Max 0.10546828806400299   Mean 0.010414911835558614\n",
      "p  13 % exact 72.22222222222221 Error:  Max 0.1423870399594307   Mean 0.015560249137796401\n",
      "p  14 % exact 68.44444444444444 Error:  Max 0.1719695404171944   Mean 0.021614912748337566\n",
      "p  15 % exact 65.83333333333333 Error:  Max 0.20805004239082336   Mean 0.027997248609447543\n",
      "p  16 % exact 63.5 Error:  Max 0.23927892744541168   Mean 0.034708088961327176\n",
      "p  17 % exact 61.111111111111114 Error:  Max 0.26866860687732697   Mean 0.04167015498193671\n",
      "p  18 % exact 58.44444444444444 Error:  Max 0.3131551668047905   Mean 0.04890585477567453\n",
      "p  19 % exact 55.722222222222214 Error:  Max 0.3364485651254654   Mean 0.05586088205998216\n"
     ]
    }
   ],
   "source": [
    "for p in range(1, 20):\n",
    "    percent_correct = np.sum(np.isclose(errors[p-1], 0.0)) /  60.0**2 *100\n",
    "    #print(f\"{p=}, {percent_correct=}, {np.max(errors[p-1])=}, {np.mean(errors[p-1])=}\")\n",
    "    print(\"p \",p, \"% exact\", percent_correct, \"Error:  Max\", np.max(errors[p-1]),  \"  Mean\", np.mean(errors[p-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [np.abs(persim_distances - d_approx[p-1]) for p in range(1, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p  1 % exact 80.55555555555556 Error:  Max 0.15655291080474865   Mean 0.003993318486545525\n",
      "p  2 % exact 93.83333333333333 Error:  Max 0.051955342292785645   Mean 0.0004415116210786263\n",
      "p  3 % exact 96.11111111111111 Error:  Max 0.05195534229278562   Mean 0.00021736337699906707\n",
      "p  4 % exact 97.33333333333334 Error:  Max 0.030719339847564475   Mean 0.00012309675829357973\n",
      "p  5 % exact 98.05555555555556 Error:  Max 0.02148166298866261   Mean 7.206694533507553e-05\n",
      "p  6 % exact 98.44444444444444 Error:  Max 0.02148166298866261   Mean 5.8784190980075584e-05\n",
      "p  7 % exact 98.77777777777777 Error:  Max 0.0095406174659729   Mean 3.2610889111067215e-05\n",
      "p  8 % exact 97.22222222222221 Error:  Max 0.0095406174659729   Mean 8.032467837207775e-05\n",
      "p  9 % exact 91.55555555555556 Error:  Max 0.025418624281883254   Mean 0.0006747377839775393\n",
      "p  10 % exact 84.0 Error:  Max 0.048307597637176514   Mean 0.0025294788823366846\n",
      "p  11 % exact 78.66666666666666 Error:  Max 0.08409188687801361   Mean 0.005956355015644568\n",
      "p  12 % exact 75.44444444444444 Error:  Max 0.10546828806400299   Mean 0.010414911835558614\n",
      "p  13 % exact 72.22222222222221 Error:  Max 0.1423870399594307   Mean 0.015560249137796401\n",
      "p  14 % exact 68.44444444444444 Error:  Max 0.1719695404171944   Mean 0.021614912748337566\n",
      "p  15 % exact 65.83333333333333 Error:  Max 0.20805004239082336   Mean 0.027997248609447543\n",
      "p  16 % exact 63.5 Error:  Max 0.23927892744541168   Mean 0.034708088961327176\n",
      "p  17 % exact 61.111111111111114 Error:  Max 0.26866860687732697   Mean 0.04167015498193671\n",
      "p  18 % exact 58.44444444444444 Error:  Max 0.3131551668047905   Mean 0.04890585477567453\n",
      "p  19 % exact 55.722222222222214 Error:  Max 0.3364485651254654   Mean 0.05586088205998216\n"
     ]
    }
   ],
   "source": [
    "for p in range(1, 20):\n",
    "    percent_correct = np.sum(np.isclose(errors[p-1], 0.0)) / 60.0**2 * 100\n",
    "    #print(f\"{p=}, {percent_correct=}, {np.max(errors[p-1])=}, {np.mean(errors[p-1])=}\")\n",
    "    print(\"p \",p, \"% exact\",percent_correct, \"Error:  Max\", np.max(errors[p-1]),  \"  Mean\", np.mean(errors[p-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine precision seems to be the issue beyond p=12 or so.  Let's look at the cost matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.430764128529048e-32,\n",
       " 62.996890640459235,\n",
       " 0.20336644990508054,\n",
       " 2.693788688751766e-07)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmat = sklearn.metrics.pairwise_distances(JustDgms_death[0], JustDgms_death[1], metric=\"chebyshev\")\n",
    "dmat = np.power(dmat, 12.0)\n",
    "np.min(dmat), np.max(dmat), np.mean(dmat), np.median(dmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks like it is the issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
